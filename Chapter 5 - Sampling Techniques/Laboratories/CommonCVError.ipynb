{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPzGEuQRI9Oo1Mt9s21SGQj"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":213},"id":"rPr0qom-UBG5","executionInfo":{"status":"ok","timestamp":1736481371332,"user_tz":300,"elapsed":303,"user":{"displayName":"Javier Eduardo Jiménez Quiteño","userId":"12185045103800847816"}},"outputId":"3f611d28-98cd-4261-8e2d-93c1f8e41281"},"outputs":[{"output_type":"stream","name":"stdout","text":["Dimensiones de X: (50, 5000)\n","Dimensiones de y: (50, 1)\n"]},{"output_type":"execute_result","data":{"text/plain":["Class\n","1        28\n","0        22\n","Name: count, dtype: int64"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>count</th>\n","    </tr>\n","    <tr>\n","      <th>Class</th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>1</th>\n","      <td>28</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>22</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div><br><label><b>dtype:</b> int64</label>"]},"metadata":{},"execution_count":5}],"source":["import numpy as np\n","import pandas as pd\n","from sklearn.datasets import make_classification\n","from sklearn.model_selection import KFold\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","\n","n_samples = 50\n","n_features = 5000\n","n_classes = 2\n","\n","\n","X = np.random.randn(n_samples, n_features)\n","\n","y = np.random.choice(n_classes, n_samples)\n","\n","\n","X_df = pd.DataFrame(X, columns=[f\"Feature_{i+1}\" for i in range(n_features)])\n","y_df = pd.DataFrame(y, columns=[\"Class\"])\n","\n","print(f\"Dimensiones de X: {X_df.shape}\")\n","print(f\"Dimensiones de y: {y_df.shape}\")\n","\n","y_df.value_counts()\n","\n"]},{"cell_type":"markdown","source":["# Wrong Way"],"metadata":{"id":"LavJfKZzUjtf"}},{"cell_type":"code","source":["top_k = 100\n","correlations = np.abs(np.corrcoef(X.T, y)[-1, :-1])\n","top_features = np.argsort(correlations)[-top_k:]\n","\n","\n","X_filtered = X[:, top_features]\n","\n","\n","kf = KFold(n_splits=5, shuffle=True, random_state=2025)\n","accuracies_incorrect = []\n","\n","for train_idx, test_idx in kf.split(X_filtered):\n","\n","    X_train, X_test = X_filtered[train_idx], X_filtered[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    model = LogisticRegression()\n","    model.fit(X_train, y_train)\n","    y_pred = model.predict(X_test)\n","\n","    accuracies_incorrect.append(accuracy_score(y_test, y_pred))\n","\n","print(f\"The accuracy obtained with the incorrect appraoch is: {np.mean(accuracies_incorrect):.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sk-QIIvxWTE1","executionInfo":{"status":"ok","timestamp":1736481857435,"user_tz":300,"elapsed":1119,"user":{"displayName":"Javier Eduardo Jiménez Quiteño","userId":"12185045103800847816"}},"outputId":"affbf70c-33c0-403e-915e-2cb1a4ca5124"},"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["The accuracy obtained with the incorrect appraoch is: 1.000\n"]}]},{"cell_type":"markdown","source":["# Correct Way"],"metadata":{"id":"5D3fuwJ0Yt--"}},{"cell_type":"code","source":["kf = KFold(n_splits=5, shuffle=True, random_state=2025)\n","accuracies_correct = []\n","\n","for train_idx, test_idx in kf.split(X):\n","\n","    X_train, X_test = X[train_idx], X[test_idx]\n","    y_train, y_test = y[train_idx], y[test_idx]\n","\n","    correlations = np.abs(np.corrcoef(X_train.T, y_train)[-1, :-1])\n","    top_features = np.argsort(correlations)[-top_k:]\n","\n","\n","    X_train_filtered = X_train[:, top_features]\n","    X_test_filtered = X_test[:, top_features]\n","\n","    model = LogisticRegression()\n","    model.fit(X_train_filtered, y_train)\n","    y_pred = model.predict(X_test_filtered)\n","\n","\n","    accuracies_correct.append(accuracy_score(y_test, y_pred))\n","\n"],"metadata":{"id":"WSQMc3w7Xm8P","executionInfo":{"status":"ok","timestamp":1736481862448,"user_tz":300,"elapsed":3007,"user":{"displayName":"Javier Eduardo Jiménez Quiteño","userId":"12185045103800847816"}}},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":["# Reality vs Expectation"],"metadata":{"id":"rphDDWe6YGrN"}},{"cell_type":"code","source":["print(f\"The accuracy obtained with the incorrect appraoch is: {np.mean(accuracies_incorrect):.3f}\")\n","print(f\"The accuracy obtained with the correct approach is: {np.mean(accuracies_correct):.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6Q7ljo9cYKwl","executionInfo":{"status":"ok","timestamp":1736481842484,"user_tz":300,"elapsed":295,"user":{"displayName":"Javier Eduardo Jiménez Quiteño","userId":"12185045103800847816"}},"outputId":"72f3a95c-8100-4b39-f8c2-486871d8fe79"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["The accuracy obtained with the incorrect appraoch is: 1.000\n","The accuracy obtained with the correct approach is: 0.580\n"]}]},{"cell_type":"markdown","source":["# Why this happens?\n","\n","This happens because when you perform feature selection (top_features filtering), you are not separating the training and test sets beforehand. As a result, you're using information from the test set when selecting features, which causes data leakage. This means that the features are being 'optimized' based on the test data, leading to overly optimistic model performance during cross-validation.\n","\n","In this example, we have 5k features, and given the large number of features, there is a high probability that some of them will appear correlated with the target variable purely by chance. This is due to the huge number of possible relationships between features and the target, and these correlations may not represent real patterns, but rather noise. This phenomenon is called cherry-picking\n","\n","If you have a large amount of data, you can split the dataset into a training and a test set at the beginning and use only the training set for feature selection. However, when data is limited, this approach can lead to overfitting because the model is tuned too much to a specific set of features. In this case, using K-fold cross-validation is essential, as it ensures that the feature selection and model training process is evaluated across different subsets of data, providing a more robust estimate of model performance and minimizing the risk of overfitting.\n","\n","**Disadvantages of the Correct Approach.**\n","\n","In the K-Fold approach, for each fold, you are selecting a different subset of 100 features. This means that, across the different folds, the specific features included in the model may change slightly. As a result, the interpretability of the model can become more challenging because the selected features—and their associated coefficients—may vary across the folds. This variability can make it harder to draw clear conclusions about which features are truly important for the model’s predictions."],"metadata":{"id":"J7sWbxAWYT3k"}}]}